# Neural Network
### Work In Progress
This is my attempt to code a neural network from scratch after studying how deep learning really works.

## Activation functions
* Linear (Identity)
* Sigmoid (Logistic)
* ReLU (Rectified linear unit)
* TanH

## Loss functions
* MSE (Mean squared error)
* Binary cross entropy
